{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_tabnet\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.augmentations import ClassificationSMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from Utility import *\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "adam = sgd = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 50, p = 6, d = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(50, 6, 4)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_50_6_4 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_50_6_4, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_50_6_4, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 50, p = 60, d = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(50, 60, 40)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_50_60_40 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_50_60_40, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_50_60_40, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 50, p = 600, d = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(50, 600, 400)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_50_600_400 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_50_600_400, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_50_600_400, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 500, p = 60, d = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(500, 60, 40)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_500_60_40 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_500_60_40, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_500_60_40, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 500, p = 600, d = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(500, 600, 400)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_500_600_400 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_500_600_400, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_500_600_400, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 5000, p = 6, d = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(5000, 6, 4)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_5000_6_4 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_5000_6_4, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_5000_6_4, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 5000, p = 60, d = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(5000, 60, 40)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_5000_60_40 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_5000_60_40, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_5000_60_40, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD; N = 5000, p = 600, d = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, info = get_files(5000, 600, 400)\n",
    "data, relevant_nodes, irrelevant_nodes, random_nodes = reorder_data(data, info)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, cat_idxs, cat_dims = preprocess(data)\n",
    "clf = generate_classifier(cat_idxs, cat_dims, optimizer = sgd)\n",
    "clf_sgd_5000_600_400 = train(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances, relevant, irrelevant, random, violin_plot = compute_importance(clf_sgd_5000_600_400, relevant_nodes, irrelevant_nodes, random_nodes)\n",
    "print(\"Average relevant feature importance:\", np.mean(relevant))\n",
    "print(\"Average irrelevant feature importance:\", np.mean(irrelevant))\n",
    "print(\"Average random feature importance:\", np.mean(random))\n",
    "\n",
    "train_auc, valid_auc, test_auc = compute_auc(clf_sgd_5000_600_400, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "print(\"Train AUC score:\", train_auc)\n",
    "print(\"Validation AUC score:\", valid_auc)\n",
    "print(\"Test AUC score:\", test_auc)\n",
    "\n",
    "fn_relevant, fp_irrelevant, fp_random = false_rates(feature_importances, relevant, irrelevant, random)\n",
    "print(\"False negative rate for relevant features:\", fn_relevant)\n",
    "print(\"False positive rate for irrelevant features:\", fp_irrelevant)\n",
    "print(\"False positive rate for random features:\", fp_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
